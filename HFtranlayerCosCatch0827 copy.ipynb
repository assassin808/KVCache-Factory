{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d898cf40-f34b-4312-a10f-2a8c6ca72807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c11622-5440-467c-be9a-69e8e1d5dc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2003916ba41490dbf48aeec3f862f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae966f4-7043-4587-a261-c913068433e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c555fef5af48948cb759582516b5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import csv\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",  output_attentions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4e073e-aba4-4355-85db-ec6db1fb9376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea3cd30-9bf8-4350-97db-97f46ceb0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Once upon a time, in a quaint little village nestled between rolling hills and lush forests, there existed a village named Green Valley, was home to villagers who lived peaceful and harmonious lives. A clear stream flowed through the village, nourishing the fields and orchards on its banks. Every morning, the villagers would rise early to begin their day’s work. The men worked in the fields, the women wove and cooked at home, and the children studied at the village school.In the village lived an elderly man named Grandpa Li, the village sage. Villagers would seek his advice whenever they faced difficulties. Grandpa Li was not only knowledgeable but also a great storyteller. Every evening, villagers would gather in front of his house to listen to his tales of ancient legends and magical adventures.One day, a stranger arrived in the village. He introduced himself as a traveler named Amin, carrying a mysterious package filled with strange items. The villagers, curious about Amin, gathered around to ask about his origins and experiences. Amin smiled and told them he came from a distant land in the East, having traveled to many places and witnessed many wonders.Amin decided to stay in the village, leading the villagers on explorations of the surrounding forests and hills, uncovering hidden treasures and secrets. Under his guidance, the villagers discovered rare flowers, plants, and animals they had never seen before. Amin also taught them new skills and knowledge, enriching their lives.However, Amin’s arrival was not by chance. He was guided by an ancient prophecy to Green Valley, seeking a legendary mystical power said to be hidden in the village. This power could only be found by those who were pure of heart and brave. Amin believed the villagers of Green Valley were the ones he was looking for.Amin decided to share this secret with the villagers. He gathered them under the big tree in the village and told them about the ancient prophecy. The villagers were both surprised and excited, eager to help Amin find this mystical power. Thus, under Amin’s leadership, they embarked on a journey filled with adventures and challenges.They traversed dense forests, climbed steep mountains, and overcame numerous obstacles. Eventually, they found the mystical power in a hidden cave. This power not only made the village more prosperous but also purified and elevated the villagers’ spirits.From then on, Green Valley became even more beautiful and harmonious, and the villagers grew more united and loving. Amin continued his journey, seeking more miracles and adventures. The story of Green Valley spread far and wide, told by Grandpa Li to all who would listen.\"\n",
    "\n",
    "tokenized_input = tokenizer(input_text, return_tensors=\"pt\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd832686-0589-4a90-ba63-e722290c8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference and obtain attention weights for all layers\n",
    "outputs = model(**tokenized_input)\n",
    "all_attention_weights = outputs.attentions  # This is a tuple of tensors\n",
    "# Extract hidden states\n",
    "all_hidden_states = outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5333e4b-a85d-4f75-b4dd-48da853607b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, hidden_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_hidden_states\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hidden state shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_state\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i, hidden_state in enumerate(all_hidden_states):\n",
    "    print(f\"Layer {i} hidden state shape: {hidden_state.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1955e1bd-d48c-453f-a7ec-f3b3f8324fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注意力分数矩阵已按层和head保存至不同的CSV文件中\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'][0])\n",
    "\n",
    "# 遍历每一层的注意力权重\n",
    "for layer_idx, attention_weights in enumerate(all_attention_weights):\n",
    "    # 去掉batch维度\n",
    "    attention_weights = attention_weights.squeeze(0).detach().numpy()\n",
    "    \n",
    "    # 遍历每个head\n",
    "    num_heads = attention_weights.shape[0]\n",
    "    for head_idx in range(num_heads):\n",
    "        # 为每个层和head组合创建一个CSV文件\n",
    "        file_name = f'attention_weights_layer_{layer_idx + 1}_head_{head_idx + 1}.csv'\n",
    "        with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # 写入CSV的表头（横轴tokens）\n",
    "            writer.writerow([''] + tokens)\n",
    "            \n",
    "            # 遍历每个token对\n",
    "            for i, token1 in enumerate(tokens):\n",
    "                # 获取当前行对应的注意力分数\n",
    "                row_attention_scores = attention_weights[head_idx, i, :]\n",
    "                \n",
    "                # 写入当前行的token和对应的注意力分数\n",
    "                writer.writerow([token1] + list(row_attention_scores))\n",
    "\n",
    "print(\"注意力分数矩阵已按层和head保存至不同的CSV文件中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7334e8-0e5e-4a08-9d00-9d354710275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有相邻层不同注意力头的余弦相似度矩阵已保存到CSV文件。\n"
     ]
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "# 遍历所有相邻层进行比较\n",
    "for layer_idx in range(num_layers - 1):\n",
    "    # 获取当前层和下一层的 hidden states\n",
    "    layer_hidden_states = all_hidden_states[layer_idx][batch_idx] \n",
    "    \n",
    "    # 对于每个头，计算相邻层之间的余弦相似度\n",
    "\n",
    "    # Normalize hidden states\n",
    "    norm_layer_hidden_states = layer_hidden_states / layer_hidden_states.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Calculate cosine similarity between tokens across layers\n",
    "    cosine_similarity = torch.mm(norm_layer_hidden_states, norm_layer_hidden_states.T)\n",
    "\n",
    "    # Create a mask for the lower triangle of the matrix\n",
    "    num_tokens = cosine_similarity.size(0)\n",
    "    mask = np.tril(np.ones((num_tokens, num_tokens)), k=0)\n",
    "\n",
    "    # Apply the mask to the cosine similarity matrix\n",
    "    masked_similarity = cosine_similarity.detach().numpy() * mask\n",
    "\n",
    "    # 将相似度矩阵保存到CSV文件\n",
    "    csv_filename = f\"HS_cos_sim_layer_{layer_idx}.csv\"\n",
    "    with open(csv_filename, mode='w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        for row in masked_similarity:\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "print(\"所有相邻层不同注意力头的余弦相似度矩阵已保存到CSV文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a0520-2aa3-4b76-90bb-1d6b7f21bea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
